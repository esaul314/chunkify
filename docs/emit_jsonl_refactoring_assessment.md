# emit_jsonl.py Refactoring Assessment

**Date:** 2026-01-23 (Final)  
**Status:** âœ… **COMPLETE**

## Module Structure (After Refactoring)

| Module | Lines | Purpose |
|--------|-------|--------|
| `emit_jsonl.py` | 1,196 | Main JSONL emission pass |
| `emit_jsonl_text.py` | 225 | Text manipulation utilities |
| `emit_jsonl_lists.py` | 492 | List detection/manipulation |
| **Total** | 1,913 | (was 1,656 monolith) |

---

## Status: All Phases Complete

This document tracked the refactoring of `emit_jsonl.py`. **All phases are now complete.**
See [Completed Work](#completed-work) for details and [merge_strategy_design.md](merge_strategy_design.md) for the technical design.

### Quick Reference for Continuing Agents

| Artifact | Purpose |
|----------|---------|
| `EmitConfig` dataclass | Centralized configuration; use `_config()` to access |
| `_merge_items_core()` | Unified merge infrastructure; all merge functions delegate here |
| `emit_jsonl_text.py` | Text utilities: overlap, caption, sentence detection |
| `emit_jsonl_lists.py` | List utilities: detection, rebalancing, reservation |
| `tests/emit_jsonl_merge_test.py` | 50 characterization tests locking down merge behavior |
| `docs/merge_strategy_design.md` | Technical design for merge consolidation |

---

## Executive Summary

**Is refactoring necessary?** Yes.  
**Is significant improvement possible?** Yes, with careful incremental work.  
**Final status:** âœ… All phases complete. Module decomposed into 3 focused files.

The `emit_jsonl.py` module has grown organically to handle numerous edge cases in text chunking, deduplication, and list handling. The refactoring effort successfully addressed this by:

1. âœ… Centralizing configuration in `EmitConfig` dataclass
2. âœ… Adding debug logging to merge decision points
3. âœ… Creating characterization tests before refactoring
4. âœ… Decomposing complex predicates into named functions
5. âœ… Unifying merge functions through `_merge_items_core()`
6. âœ… Extracting text utilities to `emit_jsonl_text.py` (225 lines)
7. âœ… Extracting list utilities to `emit_jsonl_lists.py` (492 lines)
8. âœ… Simplifying `_split` from accumulate/step to explicit while loop
9. âœ… Adding comprehensive docstrings to `_dedupe` and `_merge_sentence_pieces`

---

## Completed Work

### Phase 1: Safe Foundation (Complete)

**Commit:** `a356c30` â€” Extract EmitConfig dataclass
- Created frozen `EmitConfig` dataclass centralizing 8 environment variables
- Added `from_env()` classmethod for configuration loading
- Legacy wrapper functions delegate to config instance

**Commit:** `f2abfe7` â€” Add merge decision logging
- Added module-level `_log` logger
- Debug logging in `_merge_incomplete_lists`, `_merge_very_short_forward`, `_merge_short_rows`
- Logs merge reason, word counts, and character sizes

**Commit:** `f21f6f0` â€” Write characterization tests
- Created `tests/emit_jsonl_merge_test.py` with 31 tests
- Tests lock down behavior of all three merge functions
- Tests for `_has_incomplete_list` and `_coherent` predicates

### Phase 2: Consolidation (Complete)

**Commit:** `44a7027` â€” Decompose _has_incomplete_list
- Extracted 4 named predicates:
  - `_count_list_items()`: Count bullet and numbered items
  - `_ends_with_list_intro_colon()`: Detect colon-ending intro
  - `_has_single_inline_bullet()`: Detect inline bullet pattern
  - `_has_unterminated_bullet_item()`: Detect intro + unterminated bullet
- Rewrote `_has_incomplete_list` as composition of predicates
- Added 19 unit tests for predicates (50 total)

**Commit:** `cc8c96c` â€” Design doc for merge consolidation
- Created `docs/merge_strategy_design.md`
- Analyzed 3 merge functions for common patterns
- Recommended Option B (callable predicates) over Protocol abstraction

**Commit:** `4fea3ef` â€” Unify merge functions with _merge_items_core
- Created `_merge_items_core()` with pluggable predicates
- Type aliases: `ShouldHoldFn`, `ShouldPreserveFn`, `MergeTextFn`
- Refactored `_merge_very_short_forward` and `_merge_short_rows` to use core
- 201 insertions, 169 deletions (net reduction in complexity)

### Phase 3: Module Decomposition (Complete)

**Commit:** `8c39a15` â€” Extract text utilities to emit_jsonl_text.py
- Created `emit_jsonl_text.py` with 17 text manipulation functions
- Includes: `word_count`, `normalize`, `overlap_len`, `trim_overlap`, caption detection
- 225 lines of focused, testable utilities

**Commit:** `bc08239` â€” Extract list utilities to emit_jsonl_lists.py
- Created `emit_jsonl_lists.py` with 17 list detection/manipulation functions
- Includes: `is_list_line`, `rebalance_lists`, `reserve_for_list`, `has_incomplete_list`
- 492 lines of focused, testable utilities

**Commit:** `f6303cb` â€” Simplify _split with explicit while loop
- Replaced `accumulate/repeat/step` closure pattern with straightforward while loop
- Added inline comments explaining each step
- Easier to debug and modify

**Commit:** `336cd55` â€” Improve docstrings for _dedupe and _merge_sentence_pieces
- Added comprehensive docstrings explaining algorithm and state semantics
- The `reduce/step` pattern is idiomatic Python; documentation preferred over restructuring

### Decisions Made

| Task | Decision | Rationale |
|------|----------|----------|
| Convert `_merge_incomplete_lists` to core | NOT DONE | Uses peek-ahead pattern incompatible with single-pass core |
| Replace `_dedupe` step closure | NOT DONE | `reduce` pattern is idiomatic; documented instead |
| Extract list handling | âœ… DONE | `emit_jsonl_lists.py` created (492 lines) |

---

## Maintainability Assessment

### Does this refactoring improve maintainability?

**Yes, demonstrably.** Here's the evidence:

#### Before Refactoring
- **Configuration**: 8+ scattered `os.getenv()` calls, each re-reading environment
- **Merge functions**: 3 functions with ~90 lines each, duplicating loop structure
- **Debugging**: Required tracing through multiple similar functions to understand merge decisions
- **Testing**: No dedicated tests for merge functions
- **Predicates**: `_has_incomplete_list` was 61 lines with 11 conditionals, opaque logic

#### After Refactoring
- **Configuration**: Single `EmitConfig` dataclass with documented fields and defaults
- **Merge functions**: Core loop in one place (`_merge_items_core`), behavior controlled by small lambdas
- **Debugging**: Unified logging with consistent format, showing reason + sizes
- **Testing**: 50 characterization tests locking down behavior
- **Predicates**: 4 named functions with clear purposes, individually testable

#### Quantitative Evidence
| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Merge function total lines | ~270 | ~180 | -33% |
| Configuration access points | 15+ | 1 (`_config()`) | Centralized |
| Merge-related tests | 0 | 50 | +50 |
| Named predicates for `_has_incomplete_list` | 0 | 4 | Decomposed |

#### Qualitative Evidence
- **Easier to modify merge behavior**: Change the predicate, not the loop
- **Easier to debug**: Log output shows exactly why merges happen
- **Easier to test**: Predicates are pure functions with clear inputs/outputs
- **Easier to understand**: `should_hold` and `should_preserve` are self-documenting

---

## Complexity Metrics (Final)

| Metric | Before | After | Assessment |
|--------|--------|-------|------------|
| Main module lines | 1,656 | 1,196 | âœ… -28% reduction |
| Total lines (3 modules) | 1,656 | 1,913 | â• Better organization |
| Module count | 1 | 3 | âœ… Single-responsibility modules |
| Nested `step` functions | 3 | 1 | âœ… `_split` simplified to while loop |
| Configuration centralization | None | `EmitConfig` | âœ… Single source of truth |
| Merge-related test coverage | 0 | 66 tests | âœ… Comprehensive |

### Functions by Module

| Module | Key Functions |
|--------|--------------|
| `emit_jsonl.py` | `_split`, `_dedupe`, `_merge_items_core`, `_rows`, `emit_jsonl` |
| `emit_jsonl_text.py` | `word_count`, `trim_overlap`, `looks_like_caption_label`, `starts_mid_sentence` |
| `emit_jsonl_lists.py` | `is_list_line`, `rebalance_lists`, `reserve_for_list`, `has_incomplete_list` |

### Remaining Complex Functions

| Function | Lines | Status | Notes |
|----------|-------|--------|-------|
| `_reserve_for_list` | 70 | ğŸ”´ Unchanged | Critical complexity, not in scope |
| `_split` | 80 | âš ï¸ Unchanged | Uses nested `step` closure |
| `_merge_incomplete_lists` | 66 | âš ï¸ Partial | Called by `_merge_short_rows`, not converted to core |

---

## Key Challenges Identified

### 1. **Overlapping Merge Functions** âœ… RESOLVED

Three functions handle "merging short/incomplete content":
- `_merge_very_short_forward` (line ~1262) - merges items below threshold
- `_merge_incomplete_lists` (line ~870) - merges rows with incomplete lists  
- `_merge_short_rows` (line ~1537) - final pass merging short rows

**Resolution:** Created `_merge_items_core()` (line ~735) as unified infrastructure.
Both `_merge_very_short_forward` and `_merge_short_rows` now delegate to the core,
defining their specific behavior through `should_hold` and `should_preserve` predicates.

**Remaining:** `_merge_incomplete_lists` uses an in-place list mutation pattern 
(`rows = [*rows[:i], merged, *rows[i+2:]]`) that doesn't fit the core's forward/backward model.
It's called only from `_merge_short_rows`, so the impact is contained.

### 2. **Nested `step` Closures** âœ… PARTIALLY RESOLVED

Three functions used internal `step` closures:
- `_split` â€” **RESOLVED**: Converted to explicit while loop (commit `f6303cb`)
- `_merge_sentence_pieces` â€” **DOCUMENTED**: `reduce` pattern is idiomatic; added docstrings
- `_dedupe` â€” **DOCUMENTED**: `reduce` pattern is idiomatic; added docstrings

**Resolution:** 
- `_split` was the most opaque; now uses explicit loop with clear state variables
- `_dedupe` and `_merge_sentence_pieces` use `reduce` which is testable and idiomatic
- Added comprehensive docstrings explaining state semantics (commit `336cd55`)

### 3. **Implicit Configuration via Environment Variables** âœ… RESOLVED

The module reads 8+ environment variables:
- `PDF_CHUNKER_JSONL_MIN_WORDS`
- `PDF_CHUNKER_JSONL_META_KEY`
- `PDF_CHUNKER_JSONL_MAX_CHARS`
- `PDF_CHUNKER_TARGET_CHUNK_CHARS`
- `PDF_CHUNKER_VERY_SHORT_WORDS`
- `PDF_CHUNKER_MAX_MERGE_CHARS`
- `PDF_CHUNKER_MIN_ROW_WORDS`
- `PDF_CHUNKER_DEDUP_DEBUG`
- `PDF_CHUNKER_CRITICAL_SHORT_WORDS`

**Resolution:** Created `EmitConfig` frozen dataclass (lines 30-95) that:
- Documents all configuration with docstrings
- Provides sensible defaults
- Reads env vars in one place via `from_env()` classmethod
- Accessed through single `_config()` function

**Testing note:** `_config()` reads env vars fresh each call (no caching) to support 
test monkeypatching. The overhead is negligible.

### 4. **"Detection" vs "Action" Coupling** âœ… PARTIALLY RESOLVED

Functions like `_has_incomplete_list` both:
1. Detect a condition (returns bool)
2. Encode complex heuristics about what "incomplete" means

**Resolution:** Decomposed `_has_incomplete_list` into 4 named predicates:
- `_count_list_items(text)` â†’ (bullet_count, number_count)
- `_ends_with_list_intro_colon(lines)` â†’ bool
- `_has_single_inline_bullet(lines)` â†’ bool
- `_has_unterminated_bullet_item(lines)` â†’ bool

Now `_has_incomplete_list` is a simple composition:
```python
return (
    _ends_with_list_intro_colon(lines)
    or _has_single_inline_bullet(lines)
    or _has_unterminated_bullet_item(lines)
)
```

Each predicate is individually testable (19 new tests).

### 5. **Multiple Data Shapes** âš ï¸ NOT ADDRESSED

The module operates on:
- `Row = dict[str, Any]` - JSONL row with `text` and optional `metadata`
- `dict[str, Any]` - item from upstream passes with `text` and `meta`
- Plain `str` - text content during splitting

**Problem:** Functions accept different shapes but the type hints don't always distinguish them. `_merge_very_short_forward` takes `list[dict[str, Any]]` while `_merge_incomplete_lists` takes `list[Row]` - but `Row` is just an alias for `dict[str, Any]`.

### 6. **Call Graph Complexity** âš ï¸ PARTIALLY IMPROVED

```
_rows (entry point)
  â”œâ”€â”€ _rows_from_item
  â”‚     â””â”€â”€ _split
  â”‚           â””â”€â”€ _reserve_for_list
  â”œâ”€â”€ _merge_very_short_forward    â†’ delegates to _merge_items_core
  â”‚     â””â”€â”€ _coherent
  â”‚           â””â”€â”€ _has_incomplete_list (now uses decomposed predicates)
  â”œâ”€â”€ _coalesce
  â”‚     â””â”€â”€ _merge_items
  â”‚           â””â”€â”€ _should_merge
  â”œâ”€â”€ _dedupe
  â””â”€â”€ _merge_short_rows           â†’ delegates to _merge_items_core
        â”œâ”€â”€ _merge_incomplete_lists  (not converted - in-place mutation)
        â”‚     â””â”€â”€ _has_incomplete_list
        â””â”€â”€ _coherent
              â””â”€â”€ _has_incomplete_list
```

**Improvement:** Two of three merge paths now share `_merge_items_core`, reducing 
duplication and making behavior more predictable. The decomposed predicates make
`_has_incomplete_list` logic transparent.

**Remaining complexity:** `_merge_incomplete_lists` still uses in-place list mutation
and doesn't fit the core model.

---

## Proposed Refactoring Avenues

### Avenue 1: Extract Configuration Object âœ… COMPLETE

**Status:** Implemented in commit `a356c30`.

`EmitConfig` dataclass (lines 30-95) now centralizes all 9 configuration parameters:
- `target_chunk_chars`, `max_chars`, `min_row_words`
- `very_short_threshold`, `max_merge_chars`, `max_merge_words`
- `force_critical`, `tts_limit`
- `dedup_debug`

Accessed via `_config()` function which reads from environment fresh each call.

### Avenue 2: Consolidate Merge Functions âœ… COMPLETE

**Status:** Implemented in commits `cc8c96c` (design) and `4fea3ef` (implementation).

Created `_merge_items_core()` (lines 735-860) as unified infrastructure:

```python
def _merge_items_core(
    items: Sequence[T],
    should_hold: ShouldHoldFn[T],
    should_preserve: ShouldPreserveFn[T],
    merge_texts: MergeTextFn[T],
    max_chars: int | None = None,
    force_critical: bool = False,
) -> Iterator[T]: ...
```

Two of three merge functions now delegate to core:
- `_merge_very_short_forward` - uses local lambdas for predicates
- `_merge_short_rows` - uses `force_critical=True`

**Not converted:** `_merge_incomplete_lists` uses in-place list mutation pattern 
that would require significant redesign to fit the iterator-based core.

### Avenue 3: Replace `step` Closures with Explicit State Machines âš ï¸ NOT STARTED

**Risk:** Medium | **Value:** Medium

The `_split` function uses a complex `step` closure with `itertools.accumulate`:
```python
def _split(text: str, limit: int) -> list[str]:
    def step(state, _):
        pieces, remaining, intro_hint = state
        # ... 60 lines of logic
        return pieces, rest.lstrip(), next_intro

    states = accumulate(repeat(None), step, initial=([], text, None))
    return next(p for p, r, _ in states if not r)
```

**Proposed:**
```python
@dataclass
class SplitState:
    pieces: list[str]
    remaining: str
    intro_hint: str | None
    
    def is_complete(self) -> bool:
        return not self.remaining

class TextSplitter:
    def __init__(self, limit: int, is_list_line: Callable):
        self.limit = limit
        self.is_list_line = is_list_line
    
    def split(self, text: str) -> list[str]:
        state = SplitState([], text, None)
        while not state.is_complete():
            state = self._step(state)
        return state.pieces
    
    def _step(self, state: SplitState) -> SplitState:
        # Logic here - can be unit tested!
```

**Benefits:**
- State is explicit and inspectable
- `_step` can be unit tested directly
- Easy to add logging/tracing
- Debugger-friendly

### Avenue 4: Decompose Detection Functions âœ… COMPLETE

**Status:** Implemented in commit `44a7027`.

`_has_incomplete_list` is now composed of 4 named, testable predicates:

```python
def _count_list_items(text: str) -> tuple[int, int]:
    """Return (bullet_count, number_count) from text."""

def _ends_with_list_intro_colon(lines: list[str]) -> bool:
    """Text ends with colon introducing a list."""

def _has_single_inline_bullet(lines: list[str]) -> bool:
    """Text has exactly one inline bullet item."""

def _has_unterminated_bullet_item(lines: list[str]) -> bool:
    """Last line is a bullet item without sentence terminator."""

def _has_incomplete_list(text: str) -> bool:
    """Composite: any of the above patterns."""
    lines = text.strip().split("\n")
    return (
        _ends_with_list_intro_colon(lines)
        or _has_single_inline_bullet(lines)
        or _has_unterminated_bullet_item(lines)
    )
```

**Benefits achieved:**
- Each predicate has dedicated tests (19 new tests)
- Logic is transparent and debuggable
- Easy to add new patterns

### Avenue 5: Extract List Handling to Submodule âš ï¸ NOT STARTED

**Risk:** Medium | **Value:** High

Move all list-related logic to `pdf_chunker/passes/emit_jsonl_lists.py`:
- `_is_list_line`
- `_reserve_for_list`
- `_collapse_list_gaps`
- `_rebalance_lists`
- `_has_incomplete_list`
- `_starts_with_orphan_bullet`

**Benefits:**
- Reduces main file by ~300 lines
- List logic is cohesive and isolated
- Easier to test list handling separately

---

## Recommended Refactoring Order

### âœ… Phase 1 (COMPLETE):
- [x] Extract `EmitConfig` dataclass (commit `a356c30`)
- [x] Add logging to merge decision points (commit `f2abfe7`)
- [x] Write characterization tests for current behavior (commit `f21f6f0`)

### âœ… Phase 2 (COMPLETE):
- [x] Decompose detection functions into named predicates (commit `44a7027`)
- [x] Create design doc for merge consolidation (commit `cc8c96c`)
- [x] Consolidate merge functions into unified strategy (commit `4fea3ef`)

### âš ï¸ Phase 3 (NOT STARTED):
- [ ] Replace `step` closures with explicit state machines
- [ ] Extract list handling to submodule
- [ ] Convert `_merge_incomplete_lists` to use core infrastructure

---

## Testing Recommendations

### Completed Testing Work

- **50 characterization tests** in `tests/emit_jsonl_merge_test.py`
- **Test classes:**
  - `TestMergeVeryShortForward` (7 tests)
  - `TestMergeIncompleteLists` (8 tests)  
  - `TestMergeShortRows` (5 tests)
  - `TestHasIncompleteList` (9 tests)
  - `TestCoherent` (2 tests)
  - `TestCountListItems` (5 tests)
  - `TestEndsWithListIntroColon` (5 tests)
  - `TestHasSingleInlineBullet` (5 tests)
  - `TestHasUnterminatedBulletItem` (4 tests)

### Recommendations for Phase 3

Before refactoring `step` closures:
1. **Add property-based tests** for split/merge invariants (e.g., merged text should contain all original content)
2. **Add characterization tests** for `_split` edge cases
3. **Snapshot test** current behavior on known PDFs

During refactoring:
1. Use **snapshot testing** to detect behavior changes
2. Run **full pipeline tests** after each phase
3. Use the `--trace` flag on known problematic PDFs to verify behavior

---

## Overlap and Deduplication Interaction (Design Note)

The emit_jsonl module has multiple subsystems that remove or modify content to prevent
duplication. These interact in non-obvious ways that can cause silent data loss if
the input has certain characteristics.

### Subsystem Overview

```
Input: items[] from split_semantic
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  _rows_from_item (per-item processing)  â”‚
â”‚         â”‚                               â”‚
â”‚         â–¼                               â”‚
â”‚    _split(text, limit)                  â”‚
â”‚         â”‚                               â”‚
â”‚         â”œâ”€ _reserve_for_list()          â”‚â—„â”€â”€ Can return unexpected splits
â”‚         â”‚                               â”‚    if text matches list patterns
â”‚         â”œâ”€ _truncate_with_remainder()   â”‚
â”‚         â”‚                               â”‚
â”‚         â””â”€ _trim_overlap(prev, curr)    â”‚â—„â”€â”€ OVERLAP REMOVAL (chunk-level)
â”‚               â”‚                         â”‚    Returns "" if curr âŠ‚ prev
â”‚               â–¼                         â”‚
â”‚    _merge_sentence_pieces(pieces)       â”‚â—„â”€â”€ Re-merges mid-sentence splits
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ (all items processed)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  _dedupe(items)                         â”‚â—„â”€â”€ DEDUPLICATION (item-level)
â”‚         â”‚                               â”‚
â”‚         â”œâ”€ _contains(acc, item)         â”‚    Skips if item âŠ‚ accumulated
â”‚         â”‚                               â”‚
â”‚         â”œâ”€ _overlap_len() /             â”‚    Trims overlapping prefix
â”‚         â”‚  _prefix_contained_len()      â”‚
â”‚         â”‚                               â”‚
â”‚         â””â”€ _merge_if_fragment()         â”‚    Merges mid-sentence fragments
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
Output: deduplicated rows[]
```

### Key Interactions

#### 1. `_trim_overlap` in `_split` (Chunk-Level)

Location: `emit_jsonl_text.py:trim_overlap()`, called from `emit_jsonl.py:_split()`

**Behavior:**
```python
if contains(prev_lower, curr_lower):
    return ""  # Entire chunk dropped silently
```

**Trigger condition:** Chunk N+1 is a substring of chunk N.

**When this happens:**
- Repetitive content (same sentence repeated)
- Very short chunks from long uniform text
- Text with no natural variation (e.g., "aaa...aaa")

**Safeguards:**
- Caption labels are preserved (`looks_like_caption_label`)
- Overlap must be <90% of chunk to trigger trim (otherwise returns full chunk)
- Alphanumeric boundary check prevents mid-word breaks

#### 2. `_dedupe` (Item-Level)

Location: `emit_jsonl.py:_dedupe()`

**Behavior:**
```python
if _contains(acc_norm, text_norm):
    if log is not None:
        log.append(text)  # Only logged if dedup_debug enabled
    return state  # Item skipped entirely
```

**Trigger condition:** Item text is substring of accumulated text from all previous items.

**When this happens:**
- Upstream pass emits duplicate chunks
- Cross-page content gets duplicated during extraction
- Overlap trimming missed a case

**Safeguards:**
- `PDF_CHUNKER_DEDUP_DEBUG=1` logs dropped content
- Caption labels checked before prefix trim

#### 3. `_merge_sentence_pieces` (Re-Merge)

Location: `emit_jsonl.py:_merge_sentence_pieces()`

**Behavior:** Recombines pieces that `_split` separated if the second piece starts
with a lowercase letter (mid-sentence indicator).

**Interaction risk:** Can merge pieces back together that were intentionally split,
potentially creating chunks that exceed size limits.

#### 4. `_reserve_for_list` (Split-Point Selection)

Location: `emit_jsonl_lists.py:reserve_for_list()`

**Behavior:** Detects list patterns and adjusts split points to keep lists together.

**Interaction risk:** Text matching list patterns (e.g., "Sentence 0. Sentence 1.")
gets split at unexpected boundaries. The "intro" portion may be very short,
leaving most content as "remainder" that gets processed differently.

### Interaction Matrix

| Scenario | trim_overlap | _dedupe | _merge_sentence_pieces | Result |
|----------|--------------|---------|------------------------|--------|
| Repetitive identical text | Drops chunks | Drops items | N/A | Silent content loss |
| Text matching list pattern | Normal | Normal | Normal | Unexpected split points |
| Short chunks from uniform text | May drop | May drop | May re-merge | Unpredictable |
| Cross-page duplicate | Partial trim | Full drop | N/A | Correct (intended) |
| Caption after overlap | Preserved | Preserved | N/A | Correct (special-cased) |
| Mid-sentence + duplicate | Trim | Drop | N/A | May lose sentence fragment |

### Debugging Recommendations

1. **Enable dedup debug logging:**
   ```bash
   PDF_CHUNKER_DEDUP_DEBUG=1 pdf_chunker convert input.pdf --out out.jsonl
   ```
   This logs dropped duplicates and flags potential duplicates that survived.

2. **Use trace mode for specific phrases:**
   ```bash
   pdf_chunker convert input.pdf --trace "expected phrase" --out out.jsonl
   ```
   Generates snapshots at each pass to identify where content is lost.

3. **Test with unique content:**
   When writing tests, ensure text has unique content in each section to avoid
   triggering dedup/overlap logic unintentionally. Avoid:
   - Numbered patterns like "Item 1. Item 2." (triggers list detection)
   - Repetitive sentences (triggers containment checks)
   - Single repeated character (triggers substring containment)

### Design Rationale

The overlap and dedup systems evolved to handle real-world PDF extraction issues:

1. **PyMuPDF often extracts the same text twice** at page boundaries
2. **Headers/footers repeat** across pages and need removal
3. **Semantic chunking may create overlapping windows** that need de-duplication

The aggressive containment checks (`curr âŠ‚ prev`) are intentionalâ€”they prevent
the same sentence from appearing multiple times in the output, which would
degrade RAG retrieval quality.

**Trade-off:** The system errs on the side of removing potential duplicates,
which can cause silent data loss with pathological input (e.g., test fixtures
with repetitive content).

---

## Risks of Not Continuing

With Phases 1-2 complete, the immediate pain points are addressed:
- âœ… Configuration is centralized and testable
- âœ… Merge logic has unified infrastructure
- âœ… Detection predicates are decomposed and tested

**Remaining risks if Phase 3 is not done:**
1. **`step` closures remain hard to debug** - complex state transitions in `_split`
2. **List handling is still scattered** - ~300 lines across multiple functions
3. **`_merge_incomplete_lists` is an outlier** - doesn't use the core infrastructure

These are lower priority than the original assessment indicated.

---

## Conclusion

**Phases 1 and 2 are complete.** The refactoring achieved:

1. **Centralized configuration** via `EmitConfig` dataclass
2. **Unified merge infrastructure** via `_merge_items_core()` with pluggable predicates
3. **Decomposed detection logic** via 4 named, testable predicates
4. **Comprehensive test coverage** with 50 characterization tests

**Continuing agents should:**
- Review the 6 commits to understand what changed
- Run `pytest tests/emit_jsonl_merge_test.py -v` to verify tests pass
- Consult `docs/merge_strategy_design.md` for technical details
- Consider Phase 3 only if `step` closure complexity becomes a problem

**Recommended next step:** Evaluate whether Phase 3 is needed based on actual debugging pain. The current state is stable and well-tested.
