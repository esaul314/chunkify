# emit_jsonl.py Refactoring Assessment

**Date:** 2026-01-23 (Final)  
**Status:** ‚úÖ **COMPLETE**

## Module Structure (After Refactoring)

| Module | Lines | Purpose |
|--------|-------|--------|
| `emit_jsonl.py` | 1,196 | Main JSONL emission pass |
| `emit_jsonl_text.py` | 225 | Text manipulation utilities |
| `emit_jsonl_lists.py` | 492 | List detection/manipulation |
| **Total** | 1,913 | (was 1,656 monolith) |

---

## Status: All Phases Complete

This document tracked the refactoring of `emit_jsonl.py`. **All phases are now complete.**
See [Completed Work](#completed-work) for details and [merge_strategy_design.md](merge_strategy_design.md) for the technical design.

### Quick Reference for Continuing Agents

| Artifact | Purpose |
|----------|---------|
| `EmitConfig` dataclass | Centralized configuration; use `_config()` to access |
| `_merge_items_core()` | Unified merge infrastructure; all merge functions delegate here |
| `emit_jsonl_text.py` | Text utilities: overlap, caption, sentence detection |
| `emit_jsonl_lists.py` | List utilities: detection, rebalancing, reservation |
| `tests/emit_jsonl_merge_test.py` | 50 characterization tests locking down merge behavior |
| `docs/merge_strategy_design.md` | Technical design for merge consolidation |

---

## Executive Summary

**Is refactoring necessary?** Yes.  
**Is significant improvement possible?** Yes, with careful incremental work.  
**Final status:** ‚úÖ All phases complete. Module decomposed into 3 focused files.

The `emit_jsonl.py` module has grown organically to handle numerous edge cases in text chunking, deduplication, and list handling. The refactoring effort successfully addressed this by:

1. ‚úÖ Centralizing configuration in `EmitConfig` dataclass
2. ‚úÖ Adding debug logging to merge decision points
3. ‚úÖ Creating characterization tests before refactoring
4. ‚úÖ Decomposing complex predicates into named functions
5. ‚úÖ Unifying merge functions through `_merge_items_core()`
6. ‚úÖ Extracting text utilities to `emit_jsonl_text.py` (225 lines)
7. ‚úÖ Extracting list utilities to `emit_jsonl_lists.py` (492 lines)
8. ‚úÖ Simplifying `_split` from accumulate/step to explicit while loop
9. ‚úÖ Adding comprehensive docstrings to `_dedupe` and `_merge_sentence_pieces`

---

## Completed Work

### Phase 1: Safe Foundation (Complete)

**Commit:** `a356c30` ‚Äî Extract EmitConfig dataclass
- Created frozen `EmitConfig` dataclass centralizing 8 environment variables
- Added `from_env()` classmethod for configuration loading
- Legacy wrapper functions delegate to config instance

**Commit:** `f2abfe7` ‚Äî Add merge decision logging
- Added module-level `_log` logger
- Debug logging in `_merge_incomplete_lists`, `_merge_very_short_forward`, `_merge_short_rows`
- Logs merge reason, word counts, and character sizes

**Commit:** `f21f6f0` ‚Äî Write characterization tests
- Created `tests/emit_jsonl_merge_test.py` with 31 tests
- Tests lock down behavior of all three merge functions
- Tests for `_has_incomplete_list` and `_coherent` predicates

### Phase 2: Consolidation (Complete)

**Commit:** `44a7027` ‚Äî Decompose _has_incomplete_list
- Extracted 4 named predicates:
  - `_count_list_items()`: Count bullet and numbered items
  - `_ends_with_list_intro_colon()`: Detect colon-ending intro
  - `_has_single_inline_bullet()`: Detect inline bullet pattern
  - `_has_unterminated_bullet_item()`: Detect intro + unterminated bullet
- Rewrote `_has_incomplete_list` as composition of predicates
- Added 19 unit tests for predicates (50 total)

**Commit:** `cc8c96c` ‚Äî Design doc for merge consolidation
- Created `docs/merge_strategy_design.md`
- Analyzed 3 merge functions for common patterns
- Recommended Option B (callable predicates) over Protocol abstraction

**Commit:** `4fea3ef` ‚Äî Unify merge functions with _merge_items_core
- Created `_merge_items_core()` with pluggable predicates
- Type aliases: `ShouldHoldFn`, `ShouldPreserveFn`, `MergeTextFn`
- Refactored `_merge_very_short_forward` and `_merge_short_rows` to use core
- 201 insertions, 169 deletions (net reduction in complexity)

### Phase 3: Module Decomposition (Complete)

**Commit:** `8c39a15` ‚Äî Extract text utilities to emit_jsonl_text.py
- Created `emit_jsonl_text.py` with 17 text manipulation functions
- Includes: `word_count`, `normalize`, `overlap_len`, `trim_overlap`, caption detection
- 225 lines of focused, testable utilities

**Commit:** `bc08239` ‚Äî Extract list utilities to emit_jsonl_lists.py
- Created `emit_jsonl_lists.py` with 17 list detection/manipulation functions
- Includes: `is_list_line`, `rebalance_lists`, `reserve_for_list`, `has_incomplete_list`
- 492 lines of focused, testable utilities

**Commit:** `f6303cb` ‚Äî Simplify _split with explicit while loop
- Replaced `accumulate/repeat/step` closure pattern with straightforward while loop
- Added inline comments explaining each step
- Easier to debug and modify

**Commit:** `336cd55` ‚Äî Improve docstrings for _dedupe and _merge_sentence_pieces
- Added comprehensive docstrings explaining algorithm and state semantics
- The `reduce/step` pattern is idiomatic Python; documentation preferred over restructuring

### Decisions Made

| Task | Decision | Rationale |
|------|----------|----------|
| Convert `_merge_incomplete_lists` to core | NOT DONE | Uses peek-ahead pattern incompatible with single-pass core |
| Replace `_dedupe` step closure | NOT DONE | `reduce` pattern is idiomatic; documented instead |
| Extract list handling | ‚úÖ DONE | `emit_jsonl_lists.py` created (492 lines) |

---

## Maintainability Assessment

### Does this refactoring improve maintainability?

**Yes, demonstrably.** Here's the evidence:

#### Before Refactoring
- **Configuration**: 8+ scattered `os.getenv()` calls, each re-reading environment
- **Merge functions**: 3 functions with ~90 lines each, duplicating loop structure
- **Debugging**: Required tracing through multiple similar functions to understand merge decisions
- **Testing**: No dedicated tests for merge functions
- **Predicates**: `_has_incomplete_list` was 61 lines with 11 conditionals, opaque logic

#### After Refactoring
- **Configuration**: Single `EmitConfig` dataclass with documented fields and defaults
- **Merge functions**: Core loop in one place (`_merge_items_core`), behavior controlled by small lambdas
- **Debugging**: Unified logging with consistent format, showing reason + sizes
- **Testing**: 50 characterization tests locking down behavior
- **Predicates**: 4 named functions with clear purposes, individually testable

#### Quantitative Evidence
| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Merge function total lines | ~270 | ~180 | -33% |
| Configuration access points | 15+ | 1 (`_config()`) | Centralized |
| Merge-related tests | 0 | 50 | +50 |
| Named predicates for `_has_incomplete_list` | 0 | 4 | Decomposed |

#### Qualitative Evidence
- **Easier to modify merge behavior**: Change the predicate, not the loop
- **Easier to debug**: Log output shows exactly why merges happen
- **Easier to test**: Predicates are pure functions with clear inputs/outputs
- **Easier to understand**: `should_hold` and `should_preserve` are self-documenting

---

## Complexity Metrics (Final)

| Metric | Before | After | Assessment |
|--------|--------|-------|------------|
| Main module lines | 1,656 | 1,196 | ‚úÖ -28% reduction |
| Total lines (3 modules) | 1,656 | 1,913 | ‚ûï Better organization |
| Module count | 1 | 3 | ‚úÖ Single-responsibility modules |
| Nested `step` functions | 3 | 1 | ‚úÖ `_split` simplified to while loop |
| Configuration centralization | None | `EmitConfig` | ‚úÖ Single source of truth |
| Merge-related test coverage | 0 | 66 tests | ‚úÖ Comprehensive |

### Functions by Module

| Module | Key Functions |
|--------|--------------|
| `emit_jsonl.py` | `_split`, `_dedupe`, `_merge_items_core`, `_rows`, `emit_jsonl` |
| `emit_jsonl_text.py` | `word_count`, `trim_overlap`, `looks_like_caption_label`, `starts_mid_sentence` |
| `emit_jsonl_lists.py` | `is_list_line`, `rebalance_lists`, `reserve_for_list`, `has_incomplete_list` |

### Remaining Complex Functions

| Function | Lines | Status | Notes |
|----------|-------|--------|-------|
| `_reserve_for_list` | 70 | üî¥ Unchanged | Critical complexity, not in scope |
| `_split` | 80 | ‚ö†Ô∏è Unchanged | Uses nested `step` closure |
| `_merge_incomplete_lists` | 66 | ‚ö†Ô∏è Partial | Called by `_merge_short_rows`, not converted to core |

---

## Key Challenges Identified

### 1. **Overlapping Merge Functions** ‚úÖ RESOLVED

Three functions handle "merging short/incomplete content":
- `_merge_very_short_forward` (line ~1262) - merges items below threshold
- `_merge_incomplete_lists` (line ~870) - merges rows with incomplete lists  
- `_merge_short_rows` (line ~1537) - final pass merging short rows

**Resolution:** Created `_merge_items_core()` (line ~735) as unified infrastructure.
Both `_merge_very_short_forward` and `_merge_short_rows` now delegate to the core,
defining their specific behavior through `should_hold` and `should_preserve` predicates.

**Remaining:** `_merge_incomplete_lists` uses an in-place list mutation pattern 
(`rows = [*rows[:i], merged, *rows[i+2:]]`) that doesn't fit the core's forward/backward model.
It's called only from `_merge_short_rows`, so the impact is contained.

### 2. **Nested `step` Closures** ‚úÖ PARTIALLY RESOLVED

Three functions used internal `step` closures:
- `_split` ‚Äî **RESOLVED**: Converted to explicit while loop (commit `f6303cb`)
- `_merge_sentence_pieces` ‚Äî **DOCUMENTED**: `reduce` pattern is idiomatic; added docstrings
- `_dedupe` ‚Äî **DOCUMENTED**: `reduce` pattern is idiomatic; added docstrings

**Resolution:** 
- `_split` was the most opaque; now uses explicit loop with clear state variables
- `_dedupe` and `_merge_sentence_pieces` use `reduce` which is testable and idiomatic
- Added comprehensive docstrings explaining state semantics (commit `336cd55`)

### 3. **Implicit Configuration via Environment Variables** ‚úÖ RESOLVED

The module reads 8+ environment variables:
- `PDF_CHUNKER_JSONL_MIN_WORDS`
- `PDF_CHUNKER_JSONL_META_KEY`
- `PDF_CHUNKER_JSONL_MAX_CHARS`
- `PDF_CHUNKER_TARGET_CHUNK_CHARS`
- `PDF_CHUNKER_VERY_SHORT_WORDS`
- `PDF_CHUNKER_MAX_MERGE_CHARS`
- `PDF_CHUNKER_MIN_ROW_WORDS`
- `PDF_CHUNKER_DEDUP_DEBUG`
- `PDF_CHUNKER_CRITICAL_SHORT_WORDS`

**Resolution:** Created `EmitConfig` frozen dataclass (lines 30-95) that:
- Documents all configuration with docstrings
- Provides sensible defaults
- Reads env vars in one place via `from_env()` classmethod
- Accessed through single `_config()` function

**Testing note:** `_config()` reads env vars fresh each call (no caching) to support 
test monkeypatching. The overhead is negligible.

### 4. **"Detection" vs "Action" Coupling** ‚úÖ PARTIALLY RESOLVED

Functions like `_has_incomplete_list` both:
1. Detect a condition (returns bool)
2. Encode complex heuristics about what "incomplete" means

**Resolution:** Decomposed `_has_incomplete_list` into 4 named predicates:
- `_count_list_items(text)` ‚Üí (bullet_count, number_count)
- `_ends_with_list_intro_colon(lines)` ‚Üí bool
- `_has_single_inline_bullet(lines)` ‚Üí bool
- `_has_unterminated_bullet_item(lines)` ‚Üí bool

Now `_has_incomplete_list` is a simple composition:
```python
return (
    _ends_with_list_intro_colon(lines)
    or _has_single_inline_bullet(lines)
    or _has_unterminated_bullet_item(lines)
)
```

Each predicate is individually testable (19 new tests).

### 5. **Multiple Data Shapes** ‚ö†Ô∏è NOT ADDRESSED

The module operates on:
- `Row = dict[str, Any]` - JSONL row with `text` and optional `metadata`
- `dict[str, Any]` - item from upstream passes with `text` and `meta`
- Plain `str` - text content during splitting

**Problem:** Functions accept different shapes but the type hints don't always distinguish them. `_merge_very_short_forward` takes `list[dict[str, Any]]` while `_merge_incomplete_lists` takes `list[Row]` - but `Row` is just an alias for `dict[str, Any]`.

### 6. **Call Graph Complexity** ‚ö†Ô∏è PARTIALLY IMPROVED

```
_rows (entry point)
  ‚îú‚îÄ‚îÄ _rows_from_item
  ‚îÇ     ‚îî‚îÄ‚îÄ _split
  ‚îÇ           ‚îî‚îÄ‚îÄ _reserve_for_list
  ‚îú‚îÄ‚îÄ _merge_very_short_forward    ‚Üí delegates to _merge_items_core
  ‚îÇ     ‚îî‚îÄ‚îÄ _coherent
  ‚îÇ           ‚îî‚îÄ‚îÄ _has_incomplete_list (now uses decomposed predicates)
  ‚îú‚îÄ‚îÄ _coalesce
  ‚îÇ     ‚îî‚îÄ‚îÄ _merge_items
  ‚îÇ           ‚îî‚îÄ‚îÄ _should_merge
  ‚îú‚îÄ‚îÄ _dedupe
  ‚îî‚îÄ‚îÄ _merge_short_rows           ‚Üí delegates to _merge_items_core
        ‚îú‚îÄ‚îÄ _merge_incomplete_lists  (not converted - in-place mutation)
        ‚îÇ     ‚îî‚îÄ‚îÄ _has_incomplete_list
        ‚îî‚îÄ‚îÄ _coherent
              ‚îî‚îÄ‚îÄ _has_incomplete_list
```

**Improvement:** Two of three merge paths now share `_merge_items_core`, reducing 
duplication and making behavior more predictable. The decomposed predicates make
`_has_incomplete_list` logic transparent.

**Remaining complexity:** `_merge_incomplete_lists` still uses in-place list mutation
and doesn't fit the core model.

---

## Proposed Refactoring Avenues

### Avenue 1: Extract Configuration Object ‚úÖ COMPLETE

**Status:** Implemented in commit `a356c30`.

`EmitConfig` dataclass (lines 30-95) now centralizes all 9 configuration parameters:
- `target_chunk_chars`, `max_chars`, `min_row_words`
- `very_short_threshold`, `max_merge_chars`, `max_merge_words`
- `force_critical`, `tts_limit`
- `dedup_debug`

Accessed via `_config()` function which reads from environment fresh each call.

### Avenue 2: Consolidate Merge Functions ‚úÖ COMPLETE

**Status:** Implemented in commits `cc8c96c` (design) and `4fea3ef` (implementation).

Created `_merge_items_core()` (lines 735-860) as unified infrastructure:

```python
def _merge_items_core(
    items: Sequence[T],
    should_hold: ShouldHoldFn[T],
    should_preserve: ShouldPreserveFn[T],
    merge_texts: MergeTextFn[T],
    max_chars: int | None = None,
    force_critical: bool = False,
) -> Iterator[T]: ...
```

Two of three merge functions now delegate to core:
- `_merge_very_short_forward` - uses local lambdas for predicates
- `_merge_short_rows` - uses `force_critical=True`

**Not converted:** `_merge_incomplete_lists` uses in-place list mutation pattern 
that would require significant redesign to fit the iterator-based core.

### Avenue 3: Replace `step` Closures with Explicit State Machines ‚ö†Ô∏è NOT STARTED

**Risk:** Medium | **Value:** Medium

The `_split` function uses a complex `step` closure with `itertools.accumulate`:
```python
def _split(text: str, limit: int) -> list[str]:
    def step(state, _):
        pieces, remaining, intro_hint = state
        # ... 60 lines of logic
        return pieces, rest.lstrip(), next_intro

    states = accumulate(repeat(None), step, initial=([], text, None))
    return next(p for p, r, _ in states if not r)
```

**Proposed:**
```python
@dataclass
class SplitState:
    pieces: list[str]
    remaining: str
    intro_hint: str | None
    
    def is_complete(self) -> bool:
        return not self.remaining

class TextSplitter:
    def __init__(self, limit: int, is_list_line: Callable):
        self.limit = limit
        self.is_list_line = is_list_line
    
    def split(self, text: str) -> list[str]:
        state = SplitState([], text, None)
        while not state.is_complete():
            state = self._step(state)
        return state.pieces
    
    def _step(self, state: SplitState) -> SplitState:
        # Logic here - can be unit tested!
```

**Benefits:**
- State is explicit and inspectable
- `_step` can be unit tested directly
- Easy to add logging/tracing
- Debugger-friendly

### Avenue 4: Decompose Detection Functions ‚úÖ COMPLETE

**Status:** Implemented in commit `44a7027`.

`_has_incomplete_list` is now composed of 4 named, testable predicates:

```python
def _count_list_items(text: str) -> tuple[int, int]:
    """Return (bullet_count, number_count) from text."""

def _ends_with_list_intro_colon(lines: list[str]) -> bool:
    """Text ends with colon introducing a list."""

def _has_single_inline_bullet(lines: list[str]) -> bool:
    """Text has exactly one inline bullet item."""

def _has_unterminated_bullet_item(lines: list[str]) -> bool:
    """Last line is a bullet item without sentence terminator."""

def _has_incomplete_list(text: str) -> bool:
    """Composite: any of the above patterns."""
    lines = text.strip().split("\n")
    return (
        _ends_with_list_intro_colon(lines)
        or _has_single_inline_bullet(lines)
        or _has_unterminated_bullet_item(lines)
    )
```

**Benefits achieved:**
- Each predicate has dedicated tests (19 new tests)
- Logic is transparent and debuggable
- Easy to add new patterns

### Avenue 5: Extract List Handling to Submodule ‚ö†Ô∏è NOT STARTED

**Risk:** Medium | **Value:** High

Move all list-related logic to `pdf_chunker/passes/emit_jsonl_lists.py`:
- `_is_list_line`
- `_reserve_for_list`
- `_collapse_list_gaps`
- `_rebalance_lists`
- `_has_incomplete_list`
- `_starts_with_orphan_bullet`

**Benefits:**
- Reduces main file by ~300 lines
- List logic is cohesive and isolated
- Easier to test list handling separately

---

## Recommended Refactoring Order

### ‚úÖ Phase 1 (COMPLETE):
- [x] Extract `EmitConfig` dataclass (commit `a356c30`)
- [x] Add logging to merge decision points (commit `f2abfe7`)
- [x] Write characterization tests for current behavior (commit `f21f6f0`)

### ‚úÖ Phase 2 (COMPLETE):
- [x] Decompose detection functions into named predicates (commit `44a7027`)
- [x] Create design doc for merge consolidation (commit `cc8c96c`)
- [x] Consolidate merge functions into unified strategy (commit `4fea3ef`)

### ‚ö†Ô∏è Phase 3 (NOT STARTED):
- [ ] Replace `step` closures with explicit state machines
- [ ] Extract list handling to submodule
- [ ] Convert `_merge_incomplete_lists` to use core infrastructure

---

## Testing Recommendations

### Completed Testing Work

- **50 characterization tests** in `tests/emit_jsonl_merge_test.py`
- **Test classes:**
  - `TestMergeVeryShortForward` (7 tests)
  - `TestMergeIncompleteLists` (8 tests)  
  - `TestMergeShortRows` (5 tests)
  - `TestHasIncompleteList` (9 tests)
  - `TestCoherent` (2 tests)
  - `TestCountListItems` (5 tests)
  - `TestEndsWithListIntroColon` (5 tests)
  - `TestHasSingleInlineBullet` (5 tests)
  - `TestHasUnterminatedBulletItem` (4 tests)

### Recommendations for Phase 3

Before refactoring `step` closures:
1. **Add property-based tests** for split/merge invariants (e.g., merged text should contain all original content)
2. **Add characterization tests** for `_split` edge cases
3. **Snapshot test** current behavior on known PDFs

During refactoring:
1. Use **snapshot testing** to detect behavior changes
2. Run **full pipeline tests** after each phase
3. Use the `--trace` flag on known problematic PDFs to verify behavior

---

## Risks of Not Continuing

With Phases 1-2 complete, the immediate pain points are addressed:
- ‚úÖ Configuration is centralized and testable
- ‚úÖ Merge logic has unified infrastructure
- ‚úÖ Detection predicates are decomposed and tested

**Remaining risks if Phase 3 is not done:**
1. **`step` closures remain hard to debug** - complex state transitions in `_split`
2. **List handling is still scattered** - ~300 lines across multiple functions
3. **`_merge_incomplete_lists` is an outlier** - doesn't use the core infrastructure

These are lower priority than the original assessment indicated.

---

## Conclusion

**Phases 1 and 2 are complete.** The refactoring achieved:

1. **Centralized configuration** via `EmitConfig` dataclass
2. **Unified merge infrastructure** via `_merge_items_core()` with pluggable predicates
3. **Decomposed detection logic** via 4 named, testable predicates
4. **Comprehensive test coverage** with 50 characterization tests

**Continuing agents should:**
- Review the 6 commits to understand what changed
- Run `pytest tests/emit_jsonl_merge_test.py -v` to verify tests pass
- Consult `docs/merge_strategy_design.md` for technical details
- Consider Phase 3 only if `step` closure complexity becomes a problem

**Recommended next step:** Evaluate whether Phase 3 is needed based on actual debugging pain. The current state is stable and well-tested.
